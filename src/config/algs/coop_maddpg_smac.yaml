# --- COMA specific parameters ---

action_selector: "cont_softmax"


runner: "parallel"

buffer_size: 10000
batch_size_run: 4
batch_size: 64

env_args:
  state_last_action: False # critic adds last action internally

# update the target network every {} training steps
target_update_interval: 1
target_update_rate: 0.99

lr: 0.01
critic_lr: 0.002
gamma: 0.95
tau: 1.

# use qmix
mixing_embed_dim: 32

# use COMA
agent_output_type: "cont_softmax"
learner: "coop_maddpg_learner"
critic_q_fn: "coma"
critic_baseline_fn: "coma"
critic_train_mode: "seq"
critic_train_reps: 1
q_nstep: 0  # 0 corresponds to default Q, 1 is r + gamma*Q, etc

name: "coop_maddpg_smac"